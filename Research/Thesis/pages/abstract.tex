\chapter{Abstract}
The rise of autonomous vehicles in the transportation industry creates new challenges and opportunities for driver-vehicle interaction. As cars gain more and more autonomy new sensors and methods are needed to ensure the driver's wellbeing and a clear communication between the driver and the digital systems in the car. One important aspect of communication is emotion and more specifically emotion recognition.\\
As part of this thesis we implement a system that can detect the faces of multiple passengers on an embedded device with very high accuracy. To achieve this, we combine a mobile convolutional neural network that was trained on a large amount of faces (Wider Face data set) with a motion tracker (KCF).\\
To choose the best approach extensive testing and benchmarking was performed on a Raspberry Pi 3 B+, assessing accuracy and performance of various approaches. As for the face detection multiple neural networks as well as the dlib HoG approach and the OpenCV implementation of the Viola Jones Algorithm were benchmarked. The quality of the face detector as well as the object tracker were then evaluated using a benchmark video which most accurately represents our use case (camera mounted inside a vehicle). The benchmark results were then used to finetune the parameters of our final implementation.\\
The tracking system achieves an average frame rate of 10 FPS with the KCF algorithm and 25 FPS with the MOSSE algorithm on the Raspberry Pi 3B+.